## Week 2 - Into the RLverse

Welcome to Week 2, in this week we will learn about Markov Decision Processes aka MDPs, the concept of state value functions and state-action value function. Then we will move on to the algorithms for policy evaluation and improvement, and finally you will implement value-iteration algorithm to find the optimal policy for an MDP.

- You have to start off by reading the remaining 2nd chapter of [Grokking RL](../GrokkingRL.pdf) from Pg 45 - 58 which will introduce you to the concept of MDPs.
- Then you should read the next chapter of the book from Pg 66 - 93 which will introduce you to policy evaluation, policy iteration and value iteration.
- Now you should read the next chapter from Pg 99 - 110 and get acquainted with basic strategies for exploration-exploitation.
- Then take a look at the [Assignment](./Assignment) folder for this week's assignment.

This week will be a bit heavy on terms and can be overwhelming, so feel free to ask any related doubts. If you are not acquainted with the concept of expectation please google it. The notation from now on can be a bit confusing so please ask and DO NOT assume anything on your own.
